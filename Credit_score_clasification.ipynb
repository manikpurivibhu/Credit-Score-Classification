{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009de314",
   "metadata": {},
   "source": [
    "# Credit Score Classification\n",
    "\n",
    "<a href=\"https://www.kaggle.com/datasets/parisrohan/credit-score-classification?select=train.csv\"> Credit Score Classification Kaggle </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c757d6",
   "metadata": {},
   "source": [
    "**Problem Statement** <br>\n",
    "You are working as a data scientist in a global finance company. Over the years, the company has collected basic bank details and gathered a lot of credit-related information. The management wants to build an intelligent system to segregate the people into credit score brackets to reduce the manual efforts.\n",
    "\n",
    "**Task** <br>\n",
    "Given a person’s credit-related information, build a machine learning model that can classify the credit score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ec041",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9abfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Credit_Score'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af3a0c",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2aa4a0",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b106b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7257acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(['ID', 'Customer_ID', 'Name', 'Month', 'SSN', 'Monthly_Inhand_Salary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86ea33",
   "metadata": {},
   "source": [
    "### Dealing with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f34fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = list(missing.index)\n",
    "missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[missing_cols].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287e82a",
   "metadata": {},
   "source": [
    "Clearly, we need to change Dtype of certian features from object to float or integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].apply(lambda x: str(x).replace(\"None\", \"0\"))\n",
    "df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].apply(lambda x: str(x).replace(\"nan\", \"0\"))\n",
    "df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].apply(lambda x: str(x).replace(\"_\", \" \"))\n",
    "\n",
    "df['Num_of_Delayed_Payment'] = pd.to_numeric(df['Num_of_Delayed_Payment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Num_Credit_Inquiries'].fillna(method='bfill', inplace=True)\n",
    "df['Num_Credit_Inquiries'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a651e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Credit_History_Age'] = df['Credit_History_Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Credit_History_Age from string dtype to float; regex then iterate over series\n",
    "\n",
    "temp = []\n",
    "df['Credit_History_Age'] = df['Credit_History_Age'].str.extract(r'(^[1-9][0-9].* \\d|[1-9].* \\d)')\n",
    "for idx, val in df['Credit_History_Age'].items():\n",
    "    if type(val)==float:\n",
    "        temp.append(np.NaN)\n",
    "        continue\n",
    "    a = float(int(val[:2])*12) + int(val[-1])\n",
    "    temp.append(a)\n",
    "df['Credit_History_Age'] = temp\n",
    "df['Credit_History_Age'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de96c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount_invested_monthly'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount_invested_monthly'] = df['Amount_invested_monthly'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Amount_invested_monthly'] = df['Amount_invested_monthly'].apply(lambda x:str(x).replace(\"nan\", \"0\"))\n",
    "df['Amount_invested_monthly'] = df['Amount_invested_monthly'].apply(lambda x:str(x).replace(\"None\", \"0\"))\n",
    "df['Amount_invested_monthly'] = pd.to_numeric(df['Amount_invested_monthly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392fdc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount_invested_monthly'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Monthly_Balance'] = df['Monthly_Balance'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Monthly_Balance'] = df['Monthly_Balance'].apply(lambda x:str(x).replace(\"None\", \"0\"))\n",
    "df['Monthly_Balance'] = df['Monthly_Balance'].apply(lambda x:str(x).replace(\"nan\", \"0\"))\n",
    "df['Monthly_Balance'] = df['Monthly_Balance'].str[:7]\n",
    "df['Monthly_Balance'] = pd.to_numeric(df['Monthly_Balance'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type_of_Loan is too chaotic to deal with, so drop it\n",
    "\n",
    "df.drop(['Type_of_Loan'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dcab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7eb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Age'] = pd.to_numeric(df['Age'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Num_of_Loan'] = df['Num_of_Loan'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Num_of_Loan'] = pd.to_numeric(df['Num_of_Loan'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Outstanding_Debt'] = df['Outstanding_Debt'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Outstanding_Debt'] = pd.to_numeric(df['Outstanding_Debt'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Changed_Credit_Limit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Changed_Credit_Limit'] = df['Changed_Credit_Limit'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Changed_Credit_Limit'] = df['Changed_Credit_Limit'].apply(lambda x:str(x).replace(\" \", \"0\"))\n",
    "df['Changed_Credit_Limit'] = df['Changed_Credit_Limit'].str[:7]\n",
    "df['Changed_Credit_Limit'] = pd.to_numeric(df['Changed_Credit_Limit'], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21757743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Annual_Income'] = df['Annual_Income'].apply(lambda x:str(x).replace(\"_\", \" \"))\n",
    "df['Annual_Income'] = pd.to_numeric(df['Annual_Income'], downcast='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246ecb2",
   "metadata": {},
   "source": [
    "### Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe474d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [column for column, is_type in (df.dtypes=='object').items() if is_type]\n",
    "print('Object type columns in dataset :', objects, '\\n\\n')\n",
    "for obj in objects:\n",
    "    print(df[obj].head(2), '\\n------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dda5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objects_dict = {column: list(df[column].unique()) for column in df.select_dtypes('object').columns} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b739f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in objects_dict.items():\n",
    "    print(k, ':', v, '\\n-----------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bc2fe",
   "metadata": {},
   "source": [
    "Ordinal features are features which can be both categorized and ranked, such as Good/Better, wehereas Nominal Features are features which can only be categorized like Male/Female. <br>\n",
    "Ordinal Features are encoded using Label Encoding technique, while Nominal features are encoded using One Hot Encoding technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_categorical_features = ['Credit_Score', 'Payment_of_Min_Amount', 'Credit_Mix']\n",
    "\n",
    "nominal_categorical_features = ['Occupation', 'Payment_Behaviour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9efed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "def LabelEncode(column):\n",
    "    df[column] = labelencoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9756bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "def oneHotEncode(df, column):\n",
    "    col_values  = objects_dict[column]\n",
    "    encoded_cols = pd.DataFrame(enc.fit_transform(df[[column]]).toarray(), columns=col_values)\n",
    "    df = df.join(encoded_cols)\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26491623",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in ordinal_categorical_features:\n",
    "    LabelEncode(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b309091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nominal_categorical_features:\n",
    "    df = oneHotEncode(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2c74d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171bb027",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7edc586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629042df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "\n",
    "sns.set(rc={\"axes.facecolor\":\"#CEE8C8\",\"figure.facecolor\":\"#FFFFF5\"})\n",
    "pallet = [\"#FAD89F\", \"#53726D\", \"#424141\", \"#FFFFF5\"]\n",
    "cmap = colors.ListedColormap([\"#ACC7EF\", \"#FAD89F\", \"#53726D\", \"#424141\", \"#FFFFF5\"])\n",
    "\n",
    "#Plotting following features\n",
    "features = [ \"Age\", \"Interest_Rate\", \"Delay_from_due_date\", \"Num_of_Delayed_Payment\", \"Credit_Mix\"]\n",
    "print(\"Relative Plot Of Features\")\n",
    "plt.figure(figsize=(20,20))  \n",
    "sns.pairplot(df[features], hue= \"Credit_Mix\", palette= ([\"#ACC7EF\", \"#FAD89F\", \"#53726D\", \"#424141\"]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa7493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d2a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "\n",
    "corrmat= df.corr()\n",
    "plt.figure(figsize=(20,20))  \n",
    "sns.heatmap(corrmat, annot=True, cmap=cmap, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7beb33",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_pipeline_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e20f2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba4838",
   "metadata": {},
   "source": [
    "## Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41479542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# The DropColumns class inherits from the sklearn.base classes (BaseEstimator, TransformerMixin)\n",
    "# This makes it compatible with scikit-learn’s Pipelines\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Drop columns from DataFrame\n",
    "    Inherit from the sklearn.base classes (BaseEstimator, TransformerMixi) to make this compatible with scikit-learn’s Pipelines\n",
    "    '''\n",
    "    \n",
    "    # initializer \n",
    "    def __init__(self, columns):\n",
    "        # list of columns we derived that needs to be dropped\n",
    "        self.columns = columns\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):    #, columns\n",
    "        # self.columns = columns\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # return the dataframe with dropped features\n",
    "        df_cols = list(X.columns)\n",
    "        for col in self.columns:\n",
    "            if col in df_cols:\n",
    "                X.drop(col, axis=1, inplace=True)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa6401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11c5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class str_to_num(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Convert DataFrame columns from Object Dtype to numeric Dtype while performing general cleaning for this dataset\n",
    "    Inherit from the sklearn.base classes (BaseEstimator, TransformerMixi) to make this compatible with scikit-learn’s Pipelines\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    \n",
    "    def custom_feature_handling(self, X):\n",
    "        '''\n",
    "        Convert 'Credit_History_Age' feature from Object Dtype to float; regex then iterate over series to capture from string\n",
    "        fill empty data pointss in 'Num_Credit_Inquiries' column\n",
    "        '''\n",
    "        \n",
    "        self.temp = np.empty([X.shape[0], 1], dtype=float)\n",
    "        X['Credit_History_Age'] = X['Credit_History_Age'].str.extract(r'(^[1-9][0-9].* \\d|[1-9].* \\d)')\n",
    "        for idx, val in X['Credit_History_Age'].items():\n",
    "            if type(val)==float:\n",
    "                self.temp[idx] = np.NaN\n",
    "                continue\n",
    "            value = float(int(val[:2])*12) + int(val[-1])\n",
    "            self.temp[idx] = value\n",
    "        # could run into problem in the below line: X[col] = numpy array\n",
    "        X['Credit_History_Age'] = self.temp\n",
    "        X['Credit_History_Age'].fillna(0, inplace=True)\n",
    "        \n",
    "        #fill 'Num_Credit_Inquiries' NaN points with back fill method\n",
    "        X['Num_Credit_Inquiries'].fillna(method='bfill', inplace=True)        \n",
    "        return X\n",
    "    \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for column in self.columns:\n",
    "            # changes 'None' and 'nan' (str) type to numeric and '_' (invalid) to None in row-wise operation\n",
    "            X[column] = pd.to_numeric(X[column], errors='coerce')\n",
    "        X = self.custom_feature_handling(X)\n",
    "        X = X.fillna(0)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f846d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160a7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorical_encoding(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Perform Categorical encoding on Ordinal and Nominal Categorical features accordingly\n",
    "    Inherit from the sklearn.base classes (BaseEstimator, TransformerMixi) to make this compatible with scikit-learn’s Pipelines\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.ordinal_categorical_features = ['Payment_of_Min_Amount', 'Credit_Mix', 'Credit_Score'] \n",
    "        self.nominal_categorical_features = ['Occupation', 'Payment_Behaviour']\n",
    "        self.features_category_dict = {'Credit_Mix': ['_', 'Good', 'Standard', 'Bad'], 'Payment_of_Min_Amount': ['No', 'NM', 'Yes'], 'Credit_Score': ['Good', 'Standard', 'Poor'],\n",
    "                             'Occupation': ['Scientist', '_______', 'Teacher', 'Engineer', 'Entrepreneur', 'Developer', 'Lawyer', 'Media_Manager', 'Doctor', 'Journalist', 'Manager', 'Accountant', 'Musician', 'Mechanic', 'Writer', 'Architect'], \n",
    "                             'Payment_Behaviour': ['High_spent_Small_value_payments', 'Low_spent_Large_value_payments', 'Low_spent_Medium_value_payments', 'Low_spent_Small_value_payments', 'High_spent_Medium_value_payments', '!@9#%8', 'High_spent_Large_value_payments']}\n",
    "        self.labelencoder = LabelEncoder()\n",
    "        self.ordinalencoder = OneHotEncoder()\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # labelencoding\n",
    "        for col in self.ordinal_categorical_features:\n",
    "            X[col] = self.labelencoder.fit_transform(X[col])\n",
    "        # onehotencoding\n",
    "        for col in self.nominal_categorical_features:\n",
    "            col_values = self.features_category_dict[col]\n",
    "            encoded_cols = pd.DataFrame(self.ordinalencoder.fit_transform(X[[col]]).toarray(), columns=col_values)\n",
    "            X = X.join(encoded_cols)\n",
    "            X.drop(col, axis=1, inplace=True)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1d769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardscaler transformer for selected features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "class scaler(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    implement StandardScaler from sklearn.preprocessing module on selected features/columns\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.is_fitted = False\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        self.scaler.fit(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        if not self.is_fitted:\n",
    "            raise Exception(\"call fit() before transform() on X\")\n",
    "        X[self.columns] = self.scaler.transform(X[self.columns])\n",
    "        return X\n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        X[self.columns] = self.scaler.fit_transform(X[self.columns])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0ebae",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f1f41a",
   "metadata": {},
   "source": [
    "### Using custom transformers to create ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d60f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['ID', 'Customer_ID', 'Name', 'Month', 'SSN', 'Monthly_Inhand_Salary', 'Type_of_Loan']\n",
    "str_columns = ['Num_of_Delayed_Payment', 'Amount_invested_monthly', 'Monthly_Balance', 'Age', 'Num_of_Loan', 'Outstanding_Debt', 'Changed_Credit_Limit', 'Annual_Income']\n",
    "scale_cols = ['Age', 'Annual_Income', 'Num_Bank_Accounts', 'Num_Credit_Card', 'Interest_Rate', 'Num_of_Loan', 'Delay_from_due_date', 'Num_of_Delayed_Payment', \n",
    "              'Changed_Credit_Limit', 'Num_Credit_Inquiries', 'Credit_Mix', 'Outstanding_Debt', 'Credit_Utilization_Ratio', 'Credit_History_Age',\n",
    "              'Payment_of_Min_Amount', 'Total_EMI_per_month', 'Amount_invested_monthly', 'Monthly_Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb42c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42cb5c34",
   "metadata": {},
   "source": [
    "### `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb2863e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (26) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab349f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "custom_transformers = [('drop', DropColumns(columns=drop_columns)), ('convert', str_to_num(columns=str_columns)),  \n",
    "                ('encode', categorical_encoding()), ('StandardScaler', scaler(columns=scale_cols))]     \n",
    "    \n",
    "transformers = Pipeline(custom_transformers)\n",
    "# transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb387f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformers.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002accd9",
   "metadata": {},
   "source": [
    "### train_test_split\n",
    "\n",
    "Create pipeline of data transformations and split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc40094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = X.drop('Credit_Score', axis=1), X['Credit_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f7c5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493de15",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744da47",
   "metadata": {},
   "source": [
    "## Machine Learning for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82845bd8",
   "metadata": {},
   "source": [
    "### import libraries for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d7dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678e59d",
   "metadata": {},
   "source": [
    "### import libraries for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd03e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=3)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dectree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randfor = RandomForestClassifier()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a706cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53bfd4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(algorithms):\n",
    "    evaluation = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'Cross Validation Score', 'Confusion Matrix'])\n",
    "    for algo in algorithms:\n",
    "        algo.fit(X_train, y_train)\n",
    "        pred = algo.predict(X_test)\n",
    "        accuracy = round(metrics.accuracy_score(pred, y_test), 4)\n",
    "        cross_val = cross_val_score(algo, X, y, cv=5).mean()\n",
    "        conf_matrix = confusion_matrix(pred, y_test) \n",
    "        performance = pd.Series([algo, accuracy, cross_val, conf_matrix])\n",
    "        pd.concat([evaluation, performance], axis=0)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [logreg, svm, knn, dectree, randfor, adaboost, xgb]\n",
    "result = predictions(algorithms)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5742cec9",
   "metadata": {},
   "source": [
    " ### GridSearch for best fitting Machine Learning model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e931348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GridSearch for each Machine Learning Algorithm's optimal parameters\n",
    "parameters_dict = dict() ## (key: str), (value: (ML method(), parameters))\n",
    "parameters_dict['logreg_parameters'] = (LogisticRegression(), {'C': [0.01, 0.03, 0.1, 0.3, 1, 3]})\n",
    "parameters_dict['svm_parameters'] = (SVC(), {'kernel': ('linear', 'rbf', 'poly', 'sigmoid'), 'C': [0.001,0.005,0,0.01,0.5,0.1,1,2,5,10,50,100,500,1000]})\n",
    "parameters_dict['knn_parameters'] = (KNeighborsClassifier(), {'n_neighbors': np.arange(81, 121, 2), 'weights':['uniform', 'distance']})\n",
    "parameters_dict['dectree_parameters'] = (DecisionTreeClassifier(), {'criterion':['gini','entropy', 'log_loss']})\n",
    "parameters_dict['randfor_parameters'] = (RandomForestClassifier(), {'criterion':['gini','entropy', 'log_loss']})\n",
    "parameters_dict['adaboost_parameters'] = (AdaBoostClassifier(), {'n_estimators': [10, 50, 100, 500], 'learning_rate': [0.0001, 0.001, 0.01, 0.03, 0.1, 0.3, 1], 'algorithm': ['SAMME', 'SAMME.R']})\n",
    "parameters_dict['xgb_parameters'] = (XGBClassifier(), {'nthread':[4], 'learning_rate': [0.01, 0.03, 0.1, 0.3, 1], 'max_depth': [6, 7, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['algorithm', 'best score', 'best parameters'])\n",
    "\n",
    "for algo, parameters in parameters_dict.values():\n",
    "    model = GridSearchCV(algo, parameters)\n",
    "    model.fit(X, y)\n",
    "    best_score, best_parameters = model.best_score_, model.best_params_\n",
    "    result = pd.Series([best_score, best_parameters])\n",
    "    pd.concat(results, result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59024a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb1bdc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db238b34",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a href=\"https://www.kaggle.com/code/adityaprataprathore/credit-score-classification-ml-basics\">Credit Score Classification: ML Basics </a>\n",
    "\n",
    "<a href=\"https://www.kaggle.com/code/fitrahrmdhn/cleaning-preprocessing-knn-param-tuning\">Cleaning, Preprocessing, KNN Param Tuning</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/creating-custom-transformers-for-sklearn-pipelines-d3d51852ecc1\">Creating Custom Transformers for sklearn Pipelines </a>\n",
    "\n",
    "<a href=\"https://www.andrewvillazon.com/custom-scikit-learn-transformers/\"> Creating custom scikit-learn Transformers </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ee4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0897ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc639e6",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
